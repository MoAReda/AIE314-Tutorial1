{
    "file_type": "pptx",
    "content": "Machine Learning\nLecture 1: Introduction\nRecommended Textbooks\nCourse Content\nGrading\nWhat is Machine Learning?\n“Learning is any process by which a system improves\nperformance from experience.” - Herbert Simon\nDefinition by Tom Mitchell (1997):\nMachine Learning is the study of algorithms that\nimprove their performance P\nat some task T\nwith experience E.\nA well-defined learning task is given by <P, T, E>.\nTraditional Programming\nMachine Learning\n\nComputer\n\n\n\nData Program\nOutput\n\n\n\nData Output\nProgram\n\nComputer\nExamples of tasks that are best\tsolved by using a learning algorithm\nRecognizing patterns:\nFacial identities or facial expressions\nHandwritten or spoken words\nMedical images\nGenerating patterns:\nGenerating images or motion sequences\nRecognizing anomalies:\nUnusual credit card transactions\nUnusual patterns of sensor readings in a nuclear power \tplant\nPrediction:\nFuture stock prices or currency exchange rates\n“monkey”\n“cat”\n“dog”\nWhat is Machine Learning?\nThis is “cat”\nA large amount of images\nYou write the program for learning.\nLearning ......\nMachine Learning\n≈ Looking for a Function\nSpeech Recognition\nf \nImage Recognition\nf \nDialogue System\n \t“How are you”\n \t“Cat”\nf \n \n“Hello”\n“Hi”\n(what the user said)\n(system response)\nFramework\nA set of function\nf1 \n \n“cat”\nf1 \n \n“dog”\nf2 \n \t“monkey”\nf2 \n \n“snake”\nModel\nf1 , f2 \n \n“cat”\nImage Recognition:\nf \nFramework\nA set of function\n \n“cat”\nImage Recognition:\nf \nModel\nf1 , f2 \nTraining Data\nGoodness of function f\nBetter!\n“cat”\n“dog”\nfunction input:\nfunction output: “monkey”\n\nFramework\nA set of\n \n“cat”\nImage Recognition:\nf \nModel\nf1 , f2 \nTraining Data\n“monkey”\n“cat”\n“dog”\nUsing\nf \n“cat”\nTraining\nTesting\nfunction\nStep 1\nStep 2\nStep 3\nStep 1: define a set of function\nStep 2: goodness of function\nStep 3: pick the best function\nMachine Learning is so simple ……\nSimilar to put an elephant into a refrigerator ……\nTypes of Learning\nTypes of Learning\nWhether or not they are trained with human supervision:\nSupervised (inductive) learning\nGiven: training data + desired outputs (labels)\nUnsupervised learning\nGiven: training data (without desired outputs)\nSemi-supervised learning\nGiven: training data + a few desired outputs (partially labeled)\nReinforcement learning\nRewards from sequence of actions\nSupervised Learning\nIn supervised learning, we use known or labeled data for the \ttraining data.\nThe  input  data  goes  through  the  Machine  Learning \talgorithm and is used to train the model.\nOnce the model is trained based on the known data, you \tcan  use  unknown  data  into  the  model  and  get  a  new \tresponse.\nSupervised Learning: Regression\nGiven (x1, y1), (x2, y2), ..., (xn, yn)\nLearn a function f(x)\tto predict y given x\n– y is real-valued == regression\n9\n8\n7\n6\n5\n4\n3\n2\n1\n0\n1970\n1980\n1990\n2000\n2010\n2020\nYear\nSeptember Arctic Sea Ice Extent (1,000,000 sq km)\nData from G. Witt. Journal of Statistics Education, Volume 21, Number 1\nSupervised Learning: Classification\nGiven (x1, y1), (x2, y2), ..., (xn, yn)\nLearn a function f(x)\tto predict y given x\n– y is categorical == classification\nBreast Cancer (Malignant / Benign)\n\n1(Malignant)\n\n\n0(Benign)\nTumor Size\nSupervised Learning: Classification\nTumor Size\nPredict Benign\tPredict Malignant\n\n\nTumor Size\nGiven (x1, y1), (x2, y2), ..., (xn, yn)\nLearn a function f(x)\tto predict y given x\n– y is categorical == classification\nBreast Cancer (Malignant / Benign)\n\n1(Maligant)\n\n\n0(Benign)\nSupervised Learning\nTumor Size\nAge\nx\tcan be multi-dimensional\n– Each dimension corresponds to an attribute\nUnsupervised Learning\nGiven x1, x2, ..., xn (without labels)\nOutput hidden structure behind the x’s\n– E.g., clustering\nSocial network analysis\nImage credit: NASA/JPL-Caltech/E. Churchwell (Univ. of Wisconsin, Madison)\nAstronomical data analysis\nMarket segmentation\nUnsupervised Learning\nSemi Supervised Learning\nSome photo-hosting services, such as Google Photos, are good examples of this.\nOnce\tyou\tupload\tall\tyour\tfamily\tphotos\tto\tthe\tservice,\tit\tautomatically recognizes that the same person A shows up in photos 1, 5, and 11, while\nanother person B shows up in photos 2, 5, and 7.\nThis is the unsupervised part of the algorithm (clustering). Now all the system needs is for you to tell it who these people are.\nJust one label per person, and it is able to name everyone in every photo, which is useful for searching photos.\nReinforcement Learning\nGiven a sequence of states and actions with rewards, output a policy\nPolicy is a mapping from states  actions that\ttells you what to do in a given state\n\nExamples:\nGame playing\nRobot in a maze\nAutonomous Vehicles\nThe Agent-Environment Interface\nrt1 \nst 1\n27\nDeep Learning\nDeep\tlearning\t\t(representation\tlearning)\tseeks\tto learn rich hierarchical representations (i.e. features) automatically\tthrough\tmultiple\t\tstage\tof\tfeature learning process.\nDeep Learning\nWhat Made this Possible?\nBig Data\nHardware\nDeep\nModels know where to learn from\nModels are trainable\nModels are complex\nDeep Learning God Fathers\nACM Turing Award 2019 (Nobel Prize of Computing)\nYann LeCun, Geoffrey Hinton, and Yoshua Bengio\nDeep Learning Today\nSelf-driving cars\nDeep Learning Today\nAlphaGo\nEmoticon suggestion\nMachine translation\nDeep Learning Today\nHealthcare, cancer detection\n: https://medium.com/analytics-vidhya/facial-emotion-classification-using-deep-learning-d08dd02a2d38\n: https://medium.com/@skillcate/age-detection-model-using-cnn-a-complete-guide-7b10ad717c60\nDeep Learning Today\nDeep learning in image analysis\n: https://vinodpatildev.medium.com/deep-learning-cnn-model-to-auto-detect-vehicles-number-plate-using-python-and-api-195a773a90e4\n: https://rajjha-54560.medium.com/video-classification-using-deep-neural-networks-ebf2d395598e\n: https://www.youtube.com/shorts/1tnTM6prDW8\nDeep learning in video analysis\nMain Challenges of Machine Learning\nInsufficient quantity of data training\nNon representative Training Data\nPoor-Quality Data\nIrrelevant Features\nOverfitting the Training Data\nThe\tmodel\tperforms\twell\ton\tthe\ttraining\tdata,\tbut\tit\tdoes\tnot generalize well.\nUnder-fitting the Training Data\nWhen your model is too simple to learn the underlying structure of the data",
    "meta_data": {
        "author": "unknown",
        "date": "unknown",
        "path": "Lecture 1 (ML).pptx"
    }
}